{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "data = pd.read_csv('../data/preprocessed_data.csv')\n",
    "tester = pd.read_csv('../data/data_tester.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label', 'preprocessed_text'], dtype='object')\n",
      "Index(['text', 'label', 'preprocessed_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check duplicate columns\n",
    "print(data.columns)\n",
    "print(tester.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate 'text' columns (assuming the second is unintended)\n",
    "data = data.loc[:, ~data.columns.duplicated()]\n",
    "tester = tester.loc[:, ~tester.columns.duplicated()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['text', 'label', 'preprocessed_text'], dtype='object')\n",
      "Index(['text', 'label', 'preprocessed_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print(tester.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.rename(columns={'preprocessed_text': 'text'})\n",
    "# tester = tester.rename(columns={'preprocessed_text': 'text'})\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_pandas(data)\n",
    "test_dataset = Dataset.from_pandas(tester)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b88d29b6f1447b1a7935a1a7d5fff33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed6c3c772c04d2abbad6761ed7604a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding='max_length')\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Format for PyTorch\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# Load model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  # updated parameter name\n",
    "    logging_dir=\"./logs\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [189/189 33:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.342307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.353676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.380526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=189, training_loss=0.2559496763522032, metrics={'train_runtime': 2032.5538, 'train_samples_per_second': 1.476, 'train_steps_per_second': 0.093, 'total_flos': 397402195968000.0, 'train_loss': 0.2559496763522032, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)  # Convert logits to predicted class\n",
    "y_true = predictions.label_ids  # Actual labels from test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88     12500\n",
      "           1       0.87      0.90      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n",
      "Accuracy: 0.88604\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# y_true and y_pred from previous evaluation\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Pred 0', 'Pred 1'], yticklabels=['True 0', 'True 1'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester_copy = tester.copy()  # assuming `tester` is your original DataFrame\n",
    "tester_copy['predicted_label'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(test_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# ✅ Move model to CPU\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_text' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
    "model.to(\"cpu\")  # ✅ Move model to CPU\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Placeholder storage has not been allocated on MPS device!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m      7\u001b[0m     logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m      8\u001b[0m     predicted_class \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:917\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    915\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 917\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[1;32m    918\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    919\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    920\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    921\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    922\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    923\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    924\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    925\u001b[0m )\n\u001b[1;32m    926\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m    927\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:723\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    721\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 723\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids, inputs_embeds)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_flash_attention_2:\n\u001b[1;32m    726\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask \u001b[38;5;28;01mif\u001b[39;00m (attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01min\u001b[39;00m attention_mask) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/distilbert/modeling_distilbert.py:111\u001b[0m, in \u001b[0;36mEmbeddings.forward\u001b[0;34m(self, input_ids, input_embeds)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    input_ids (torch.Tensor):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03membeddings)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m     input_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_embeddings(input_ids)  \u001b[38;5;66;03m# (bs, max_seq_length, dim)\u001b[39;00m\n\u001b[1;32m    113\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_embeds\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Setting the position-ids to the registered buffer in constructor, it helps\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# when tracing the model without passing position-ids, solves\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# issues similar to issue #5664\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx,\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type,\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq,\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse,\n\u001b[1;32m    198\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Placeholder storage has not been allocated on MPS device!"
     ]
    }
   ],
   "source": [
    "test_text = \"awesome and amazing movie\"\n",
    "\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "label_map = {0: \"Negative\", 1: \"Positive\"}\n",
    "print(f\"Predicted Sentiment: {label_map[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./models/tokenizer_config.json',\n",
       " './models/special_tokens_map.json',\n",
       " './models/vocab.txt',\n",
       " './models/added_tokens.json',\n",
       " './models/tokenizer.json')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./models\")\n",
    "tokenizer.save_pretrained(\"./models\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
