{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, pipeline  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from datasets import Dataset \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate \n",
    "import os \n",
    "import torch\n",
    "import gradio as gr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = os.path.abspath('./models/optimized_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7db4da5ebba498abe5d7d01c7d3edad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e05f80477d4159b51cefaa86f5740a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading...:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/efarooqi/sentiment_analysis/commit/887ba5b983cd018517e97fa14c1b823fd914ea09', commit_message='Upload folder using huggingface_hub', commit_description='', oid='887ba5b983cd018517e97fa14c1b823fd914ea09', pr_url=None, repo_url=RepoUrl('https://huggingface.co/efarooqi/sentiment_analysis', endpoint='https://huggingface.co', repo_type='model', repo_id='efarooqi/sentiment_analysis'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Securely fetch the token\n",
    "token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# Initialize API with token\n",
    "api = HfApi(token=token)\n",
    "\n",
    "# Upload your model folder\n",
    "api.upload_folder(\n",
    "    folder_path=\"/Users/erum/LHL_LLM/notebooks/optimized_model\",\n",
    "    repo_id=\"efarooqi/sentiment_analysis\",\n",
    "    repo_type=\"model\",\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load model and tokenizer from your saved directory\n",
    "model_path = \"/Users/erum/LHL_LLM/notebooks/optimized_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Text to test\n",
    "test_text = \"This is absolutely fantastic movie\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Run prediction\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "# Interpret the predicted class\n",
    "label_map = model.config.id2label\n",
    "print(\"Predicted Sentiment:\", label_map[predicted_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_path = \"/Users/erum/LHL_LLM/notebooks/optimized_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Prediction function\n",
    "def predict_sentiment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        label_map = model.config.id2label\n",
    "        return label_map[predicted_class]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch Gradio UI\n",
    "demo = gr.Interface(\n",
    "    fn=predict_sentiment,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Enter movie review...\"),\n",
    "    outputs=\"label\",\n",
    "    title=\"Sentiment Analysis\",\n",
    "    description=\"Enter a movie review to see whether it's classified as Positive or Negative ðŸŽ¬\"\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
